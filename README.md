# ðŸ“š FICHE DE RÃ‰VISION - TP4 POINTNET

## ðŸŽ¯ PARTIE 1 : BUT ET CONCEPT DU TP

### Objectif Principal

Le but de ce TP est de comprendre **PointNet**, un rÃ©seau de neurones qui travaille directement sur des **nuages de points 3D** pour les classifier.

### ProblÃ¨me Ã  RÃ©soudre

**Input** : Un nuage de points 3D (ex: 2048 points avec coordonnÃ©es (x, y, z))  
**Output** : La classe de l'objet (cylindre, rectangle, tore)

### Challenges Uniques des Nuages de Points

**1. Ordre des points variable (Permutation Invariance)**

```python
[p1, p2, p3] = [p3, p1, p2] = [p2, p3, p1]
```

Le rÃ©seau doit donner **la mÃªme prÃ©diction** peu importe l'ordre des points.

**2. Rotation alÃ©atoire**

L'objet peut Ãªtre tournÃ© dans n'importe quelle direction â†’ besoin d'invariance aux rotations.

**3. Pas de structure rÃ©guliÃ¨re**

- **Images** : Grille rÃ©guliÃ¨re de pixels avec voisinage spatial
- **Nuages de points** : Points dÃ©sordonnÃ©s sans structure fixe

### Solution : PointNet

**3 idÃ©es clÃ©s** :

1. **Conv1d (kernel=1)** : Traiter chaque point indÃ©pendamment
2. **MaxPooling global** : Obtenir une feature invariante Ã  l'ordre
3. **T-Net** : Apprendre Ã  aligner les objets automatiquement

**Analogie** : C'est comme reconnaÃ®tre un objet en regardant une poignÃ©e de points dans l'espace 3D, peu importe comment ils sont ordonnÃ©s ou orientÃ©s.

---

## ðŸŽ² PARTIE 2 : GÃ‰NÃ‰RATION DES DONNÃ‰ES

### Code de GÃ©nÃ©ration

```python
def sample_cylinder(npts=2048):
    # GÃ©nÃ¨re un cylindre avec 2048 points sur la surface
    
def sample_rectangle(npts=2048):
    # GÃ©nÃ¨re un parallÃ©lÃ©pipÃ¨de
    
def sample_torus(npts=2048):
    # GÃ©nÃ¨re un tore
    
def apply_random_rotation(x):
    # Rotation alÃ©atoire 3D
    
def normalize(x):
    # Centrage + normalisation [-1, 1]
```

### Ã‰chantillonnage du Cylindre - Explication DÃ©taillÃ©e

#### Calcul des Aires

```python
# ParamÃ¨tres alÃ©atoires
l = np.random.rand()  # Longueur [0, 1]
r = np.random.rand()  # Rayon [0, 1]

# Calcul des aires
a1 = 2 * Ï€ * rÂ²        # Aire des 2 cercles (caps haut et bas)
a2 = 2 * Ï€ * r * l     # Aire du tube (surface latÃ©rale)
```

#### StratÃ©gie de RÃ©partition

**Principe** : RÃ©partir les points **proportionnellement aux aires** pour un Ã©chantillonnage uniforme.

**Exemple concret** :
- Si a1 = 0.3 (30% de l'aire totale) et a2 = 0.7 (70%)
- Alors 30% des points sur les cercles, 70% sur le tube

```python
nptscirc = int(npts * a1 / (a1 + a2))  # Points sur les cercles
nptstube = npts - nptscirc              # Points sur le tube
```

#### Ã‰chantillonnage Uniforme sur un Disque

```python
u = np.random.rand(nptscirc, 2)
u[:,0] = np.sqrt(u[:,0])  # âš ï¸ Transformation cruciale !

# CoordonnÃ©es polaires â†’ cartÃ©siennes
x = u[:,0] * r * np.cos(2Ï€ * u[:,1])
y = u[:,0] * r * np.sin(2Ï€ * u[:,1])
```

#### Pourquoi `sqrt(u)` ? âš ï¸ QUESTION D'EXAMEN

**Sans sqrt** : Les points se concentrent au centre (densitÃ© non uniforme)  
**Avec sqrt** : Distribution uniforme sur le disque

**Raison mathÃ©matique** : L'aire d'un anneau augmente avec le rayon.

**Visualisation** :

```
Sans sqrt:          Avec sqrt:
  â—â—â—â—â—              â— â— â—
  â—â—â—â—â—             â— â— â— â—
  â—â—â—â—â—              â— â— â—
(densitÃ© au centre) (uniforme)
```

**Explication** : En coordonnÃ©es polaires, l'Ã©lÃ©ment d'aire est $dA = r \cdot dr \cdot d\theta$. Pour compenser le facteur $r$, on Ã©chantillonne $r$ selon $\sqrt{u}$ au lieu de $u$.

### Rotation AlÃ©atoire

```python
def apply_random_rotation(x, dim=3):
    # GÃ©nÃ¨re une base orthonormÃ©e alÃ©atoire
    u = random_vector()
    v = random_vector() - projection(u onto v)
    w = cross(u, v)
    
    M = [u, v, w]  # Matrice orthogonale
    x = x @ M      # Rotation
    return normalize(x)
```

**PropriÃ©tÃ© mathÃ©matique** : $M$ est une **matrice de rotation** â†’ $M^T M = I$ et $\det(M) = 1$

**Effet** : Chaque objet est tournÃ© alÃ©atoirement dans l'espace 3D.

---

## ðŸ”§ PARTIE 3 : T-NET (Transformation Network)

### Code du T-Net

```python
class MyTNet(nn.Module):
    def __init__(self, dim=3):
        super().__init__()
        self.dim = dim
        
        # ENCODEUR : Extraire features globales
        self.conv1 = nn.Conv1d(dim, 64, kernel_size=1)
        self.conv2 = nn.Conv1d(64, 128, kernel_size=1)
        self.conv3 = nn.Conv1d(128, 1024, kernel_size=1)
        
        # DÃ‰CODEUR : PrÃ©dire la matrice de transformation
        self.linear1 = nn.Linear(1024, 512)
        self.linear2 = nn.Linear(512, 256)
        self.linear3 = nn.Linear(256, dim*dim)
    
    def forward(self, x):
        # x: (B, dim, N) - B batches, dim canaux, N points
        
        x = F.relu(self.conv1(x))    # (B, 64, N)
        x = F.relu(self.conv2(x))    # (B, 128, N)
        x = F.relu(self.conv3(x))    # (B, 1024, N)
        
        # MaxPooling global â†’ feature globale
        x = torch.max(x, dim=2)[0]   # (B, 1024)
        
        x = F.relu(self.linear1(x))  # (B, 512)
        x = F.relu(self.linear2(x))  # (B, 256)
        x = self.linear3(x)          # (B, dim*dim)
        
        # Ajouter la matrice identitÃ©
        I = torch.eye(self.dim).view(1, dim*dim).repeat(x.size(0), 1)
        x = x + I
        
        # Reshape en matrice
        x = x.view(-1, self.dim, self.dim)  # (B, dim, dim)
        return x
```

### Concept du T-Net

**Objectif** : Apprendre une **matrice de transformation** pour aligner automatiquement l'objet dans une orientation canonique.

**Analogie** : Comme un photographe qui ajuste l'angle de la camÃ©ra pour toujours voir l'objet de face, peu importe sa position initiale.

### Exemple Concret avec 3 Points

#### Input : Cylindre TournÃ©

```python
x = [
  [0.5, 0.8, 0.2],  
  [0.3, 0.6, 0.9],  
  [0.7, 0.4, 0.1]   
]
# Shape: (1, 3, 3) = (batch=1, canaux_xyz=3, points=3)
```

#### Ã‰TAPE 1 : Conv1d avec kernel=1

```python
self.conv1 = nn.Conv1d(3, 64, kernel_size=1)
```

**Effet** : Applique une transformation linÃ©aire **indÃ©pendamment** Ã  chaque point.

**MathÃ©matiquement** : Pour chaque point $p_i$, on calcule $h_i = W \cdot p_i + b$

```python
# Pour chaque point, on applique le mÃªme poids W (64Ã—3)
# Point 1: [0.5, 0.8, 0.2] â†’ [f1, f2, ..., f64]  (64 features)
# Point 2: [0.3, 0.6, 0.9] â†’ [g1, g2, ..., g64]  (64 features)
# Point 3: [0.7, 0.4, 0.1] â†’ [h1, h2, ..., h64]  (64 features)

# Output: (1, 64, 3)
```

**Pourquoi kernel=1 ?** âš ï¸ QUESTION D'EXAMEN

- On traite chaque point **sÃ©parÃ©ment**
- Pas de notion de voisinage spatial (contrairement aux images)
- Les points n'ont pas d'ordre fixe â†’ pas de convolution classique

**DiffÃ©rence avec Conv2d** :

| Aspect | Conv2d (Images) | Conv1d kernel=1 (Points) |
|--------|----------------|--------------------------|
| **Voisinage** | Kernel 3Ã—3, 5Ã—5 | Pas de voisinage |
| **Structure** | Grille rÃ©guliÃ¨re | Points dÃ©sordonnÃ©s |
| **OpÃ©ration** | AgrÃ¨ge pixels voisins | Transforme chaque point |

#### Ã‰TAPE 2 : MaxPooling Global

```python
x = torch.max(x, dim=2)[0]  # (B, 1024, N) â†’ (B, 1024)
```

**Effet** : Pour chaque feature (1024 au total), garder la **valeur maximale** parmi tous les points.

**Exemple concret** :

```python
# AprÃ¨s Conv3: (1, 1024, 3)
x = [
  [  # Feature 0
    [0.5, 0.8, 0.2]  â†’ max = 0.8
  ],
  [  # Feature 1
    [0.3, 0.9, 0.6]  â†’ max = 0.9
  ],
  [  # Feature 2
    [0.7, 0.4, 0.1]  â†’ max = 0.7
  ],
  ...
  [  # Feature 1023
    [0.2, 0.5, 0.3]  â†’ max = 0.5
  ]
]

# AprÃ¨s MaxPool: (1, 1024)
x = [0.8, 0.9, 0.7, ..., 0.5]
```

**PropriÃ©tÃ© CRUCIALE** : Le MaxPool est **invariant Ã  l'ordre** des points ! âš ï¸

$$\max([0.5, 0.8, 0.2]) = \max([0.2, 0.5, 0.8]) = \max([0.8, 0.2, 0.5]) = 0.8$$

**Pourquoi cette propriÃ©tÃ© est essentielle** : Peu importe l'ordre des points en entrÃ©e, la feature globale reste la mÃªme â†’ le rÃ©seau est **permutation invariant**.

#### Ã‰TAPE 3 : PrÃ©diction de la Matrice

```python
x = self.linear3(x)  # (B, 9) pour dim=3

# Exemple de sortie (petits rÃ©sidus)
x = [0.1, 0.05, -0.02, 0.03, 0.08, 0.01, -0.01, 0.02, 0.09]

# Ajout de l'identitÃ©
I = [1, 0, 0, 0, 1, 0, 0, 0, 1]
x = x + I = [1.1, 0.05, -0.02, 0.03, 1.08, 0.01, -0.01, 0.02, 1.09]

# Reshape en matrice 3Ã—3
M = [[1.1,  0.05, -0.02],
     [0.03, 1.08,  0.01],
     [-0.01, 0.02, 1.09]]
```

**Pourquoi ajouter l'identitÃ© ?** âš ï¸ QUESTION D'EXAMEN

**Sans identitÃ©** : Le rÃ©seau pourrait prÃ©dire une **matrice nulle** au dÃ©but de l'entraÃ®nement
â†’ Tous les points deviennent $(0, 0, 0)$ aprÃ¨s transformation
â†’ Gradients nuls â†’ **impossible d'apprendre** !

**Avec identitÃ©** : Au dÃ©but, $M \approx I$ (transformation nulle = objet inchangÃ©)
â†’ Le rÃ©seau apprend progressivement des ajustements
â†’ $M = I + \Delta M$ oÃ¹ $\Delta M$ est petit

**Analogie** : C'est comme commencer un dessin avec un croquis de base plutÃ´t qu'une feuille blanche.

#### Ã‰TAPE 4 : Application de la Matrice

```python
# Dans PointNet forward
M = self.tnet(x)              # (B, 3, 3)
x_aligned = torch.bmm(M, x)   # Rotation des points
```

**`torch.bmm`** : Batch Matrix Multiplication

**Exemple concret** :

```python
# Points originaux (cylindre tournÃ©)
x = [[0.5, 0.3, 0.7],
     [0.8, 0.6, 0.4],
     [0.2, 0.9, 0.1]]

# Matrice prÃ©dite
M = [[1.1,  0.05, -0.02],
     [0.03, 1.08,  0.01],
     [-0.01, 0.02, 1.09]]

# Points alignÃ©s : M Ã— x
x_aligned = M @ x = [[0.54, 0.32, 0.77],
                     [0.86, 0.65, 0.44],
                     [0.21, 0.97, 0.11]]
```

**RÃ©sultat** : L'objet est maintenant dans une **orientation canonique** (toujours la mÃªme), ce qui facilite la classification.

---

## ðŸ§  PARTIE 4 : POINTNET COMPLET

### Architecture Globale

```
Input (B, 3, N)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  T-Net (3D)     â”‚ â†’ Matrice 3Ã—3
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Alignement spatial: points Ã— matrice
    â†“
Conv1d(3â†’64) â†’ Conv1d(64â†’64)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  T-Net (64D)    â”‚ â†’ Matrice 64Ã—64
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Alignement features: features Ã— matrice
    â†“
Conv1d(64â†’128) â†’ Conv1d(128â†’1024)
    â†“
MaxPooling global â†’ (B, 1024)
    â†“
FC(1024â†’512) â†’ FC(512â†’256) â†’ FC(256â†’3)
    â†“
LogSoftmax â†’ ProbabilitÃ©s de classes
```

### Code du Forward

```python
def forward(self, x):
    # x: (B, 3, N) - Batch, CoordonnÃ©es xyz, Nombre de points
    
    # ========== ALIGNEMENT SPATIAL ==========
    tn1 = self.tnet1(x)           # (B, 3, 3)
    x = torch.bmm(tn1, x)         # (B, 3, N) - Points alignÃ©s
    
    # ========== EXTRACTION FEATURES BAS NIVEAU ==========
    x = F.relu(self.fc1(x))       # (B, 64, N)
    x = F.relu(self.fc2(x))       # (B, 64, N)
    
    # ========== ALIGNEMENT FEATURES ==========
    tn2 = self.tnet2(x)           # (B, 64, 64)
    x = torch.bmm(tn2, x)         # (B, 64, N) - Features alignÃ©es
    
    # ========== FEATURES HAUT NIVEAU ==========
    x = F.relu(self.fc3(x))       # (B, 128, N)
    x = F.relu(self.fc4(x))       # (B, 1024, N)
    
    # ========== GLOBAL FEATURE (AGREGATION) ==========
    x = torch.max(x, dim=2)[0]    # (B, 1024) - Feature globale
    
    # ========== CLASSIFICATION ==========
    x = F.relu(self.fc5(x))       # (B, 512)
    x = F.relu(self.fc6(x))       # (B, 256)
    x = self.logsoftmax(self.fc7(x))  # (B, 3) - ProbabilitÃ©s log
    
    return x, tn1, tn2
```

### Flux de DonnÃ©es DÃ©taillÃ©

| Ã‰tape | Shape | OpÃ©ration |
|-------|-------|-----------|
| Input | (B, 3, N) | Nuage de points brut |
| T-Net1 | (B, 3, 3) | Matrice de rotation spatiale |
| Aligned | (B, 3, N) | Points dans orientation canonique |
| Conv 1-2 | (B, 64, N) | Features par point |
| T-Net2 | (B, 64, 64) | Matrice de rotation features |
| Aligned | (B, 64, N) | Features alignÃ©es |
| Conv 3-4 | (B, 1024, N) | Features hautes par point |
| MaxPool | (B, 1024) | **Feature globale unique** |
| FC 5-7 | (B, 3) | Scores de classes |

### Pourquoi 2 T-Nets ? âš ï¸ QUESTION D'EXAMEN

**1. T-Net1 (Input : 3D)** : 
- Aligne les **points** dans l'espace 3D
- Rotation **gÃ©omÃ©trique** (rotation physique de l'objet)
- Matrice 3Ã—3 agit sur les coordonnÃ©es (x, y, z)

**2. T-Net2 (Input : 64D)** :
- Aligne les **features** dans l'espace des caractÃ©ristiques
- Rotation **abstraite** (ajustement de la reprÃ©sentation interne)
- Matrice 64Ã—64 agit sur les 64 features par point

**Analogie** :
- **T-Net1** = Tourner la statue physiquement pour la voir de face
- **T-Net2** = Ajuster comment on "perÃ§oit" la statue (filtres mentaux)

**BÃ©nÃ©fice** : Double niveau d'invariance â†’ robustesse accrue

---

## ðŸ”’ PARTIE 5 : RÃ‰GULARISATION T-NET

### Code de RÃ©gularisation

```python
def tnet_regularization(matrix):
    # matrix: (B, k, k) - Matrices prÃ©dites par T-Net
    
    I = torch.eye(matrix.size(1)).to(matrix.device)
    MMT = torch.bmm(matrix, matrix.transpose(2, 1))  # M Ã— M^T
    loss = torch.norm(MMT - I, dim=(1, 2)).mean()
    return loss

# Dans la loss totale
reg1 = tnet_regularization(tn1)
reg2 = tnet_regularization(tn2)
loss = criterion(output, target) + 0.001 * (reg1 + reg2)
```

### Concept MathÃ©matique

**Objectif** : Forcer la matrice $M$ Ã  Ãªtre **proche d'une rotation** (matrice orthogonale).

**PropriÃ©tÃ© d'une matrice orthogonale** : 

$$M M^T = I$$

OÃ¹ $I$ est la matrice identitÃ©.

**Formule de la loss de rÃ©gularisation** :

$$L_{\text{reg}} = ||M M^T - I||_F^2$$

OÃ¹ $||\cdot||_F$ est la **norme de Frobenius** : $||A||_F = \sqrt{\sum_{i,j} A_{ij}^2}$

### Exemple Concret

```python
# Matrice prÃ©dite (non orthogonale)
M = [[1.5, 0.2, 0.1],
     [0.1, 1.4, 0.2],
     [0.2, 0.1, 1.6]]

# M Ã— M^T
M_MT = [[2.30, 0.33, 0.42],
        [0.33, 2.01, 0.42],
        [0.42, 0.42, 2.62]]

# Matrice identitÃ©
I = [[1, 0, 0],
     [0, 1, 0],
     [0, 0, 1]]

# DiffÃ©rence
diff = M_MT - I = [[1.30, 0.33, 0.42],
                   [0.33, 1.01, 0.42],
                   [0.42, 0.42, 1.62]]

# Loss de Frobenius
loss = sqrt(1.30Â² + 0.33Â² + 0.42Â² + ... + 1.62Â²) = 2.15
```

**InterprÃ©tation** : Plus la loss est Ã©levÃ©e, plus $M$ s'Ã©loigne d'une rotation pure.

### Pourquoi cette RÃ©gularisation ? âš ï¸ QUESTION D'EXAMEN

**Sans rÃ©gularisation** :
- Le T-Net pourrait apprendre des transformations **dÃ©gÃ©nÃ©rÃ©es** (ex: mise Ã  l'Ã©chelle extrÃªme, cisaillement)
- Exemple : $M$ pourrait "Ã©craser" tous les points sur un plan â†’ perte d'information
- InstabilitÃ© numÃ©rique

**Avec rÃ©gularisation** :
- Le rÃ©seau apprend des matrices **plus propres** (proches de rotations pures)
- PrÃ©serve les distances et les angles
- Meilleure gÃ©nÃ©ralisation

**Coefficient 0.001** : Ã‰quilibre entre la loss de classification et la rÃ©gularisation

---

## ðŸŽ¯ PARTIE 6 : ENTRAÃŽNEMENT AVEC BRUIT

### Code d'Augmentation

```python
def bruit(points, sigma):
    """Ajoute du bruit gaussien aux points"""
    bruit = torch.randn_like(points) * sigma
    return points + bruit

# Pendant l'entraÃ®nement
max_sigma = 0.1  # Bruit maximal de 10%
sigma = torch.rand(1).item() * max_sigma  # Ïƒ alÃ©atoire [0, 0.1]
points = bruit(points, sigma)
```

### Exemple Concret

```python
# Points originaux
points = [[0.5, 0.8, 0.2],
          [0.3, 0.6, 0.9],
          [0.7, 0.4, 0.1]]

# Bruit gaussien (Ïƒ = 0.05)
noise = [[-0.02, 0.03, -0.01],
         [0.01, -0.02, 0.04],
         [0.03, -0.01, 0.02]]

# Points bruitÃ©s
points_noisy = [[0.48, 0.83, 0.19],
                [0.31, 0.58, 0.94],
                [0.73, 0.39, 0.12]]
```

**Effet visuel** : Les points "vibrent" lÃ©gÃ¨rement autour de leur position originale.

### RÃ©sultats ExpÃ©rimentaux

| Niveau de bruit | Accuracy | Impact |
|----------------|----------|---------|
| **Sans bruit (Ïƒ=0)** | ~95% | Baseline |
| **Bruit faible (Ïƒ=0.05)** | ~92% | -3% |
| **Bruit moyen (Ïƒ=0.1)** | ~90% | -5% |
| **Bruit fort (Ïƒ=0.5)** | ~33% | Effondrement |

### Analyse

**Robustesse modÃ©rÃ©e** :
- PointNet rÃ©siste bien au bruit lÃ©ger (â‰¤10%)
- Performance se dÃ©grade rapidement au-delÃ 
- Ã€ 50% de bruit, classification alÃ©atoire (33% avec 3 classes)

**Pourquoi cette sensibilitÃ© ?**
- Le MaxPool global capture les features **les plus activÃ©es**
- Le bruit fort peut **dÃ©placer les maxima** â†’ features incorrectes
- Pas de mÃ©canisme de dÃ©bruitage explicite

**Solutions dans PointNet++** :
- Ã‰chantillonnage hiÃ©rarchique (multi-Ã©chelle)
- Groupement local de points
- Meilleure robustesse au bruit

---

## ðŸŽ“ POINTS CLÃ‰S POUR L'EXAMEN

### Questions de ComprÃ©hension Probables

**1. Qu'est-ce que PointNet ?**
- RÃ©seau de neurones pour **nuages de points 3D**
- Invariant Ã  l'**ordre** des points (MaxPool)
- Invariant aux **rotations** (T-Net)

**2. Pourquoi Conv1d avec kernel=1 ?**
- Traiter chaque point **indÃ©pendamment**
- Pas de notion de voisinage spatial (points dÃ©sordonnÃ©s)
- Applique la mÃªme transformation Ã  tous les points

**3. RÃ´le du MaxPooling global ?** âš ï¸ CRUCIAL
- AgrÃ¨ge les features de tous les points en **1 vecteur global**
- **Invariant Ã  l'ordre** : max([a, b, c]) = max([c, a, b])
- RÃ©sume l'objet entier en (B, 1024)

**4. Qu'est-ce que le T-Net ?**
- Sous-rÃ©seau qui prÃ©dit une **matrice de transformation**
- Aligne automatiquement les objets dans une orientation canonique
- 2 T-Nets : spatial (3Ã—3) et features (64Ã—64)

**5. Pourquoi ajouter l'identitÃ© dans le T-Net ?**
- Ã‰viter les transformations dÃ©gÃ©nÃ©rÃ©es au dÃ©but
- Initialisation stable (M â‰ˆ I au dÃ©part)
- Permet l'apprentissage progressif

**6. Pourquoi rÃ©gulariser le T-Net ?**
- Forcer $M$ Ã  Ãªtre **orthogonale** (rotation propre)
- Ã‰viter transformations dÃ©gÃ©nÃ©rÃ©es (Ã©crasement, cisaillement)
- Meilleure stabilitÃ© et gÃ©nÃ©ralisation

**7. DiffÃ©rence entre les 2 T-Nets ?**
- **T-Net1** : Aligne les points dans l'espace 3D (gÃ©omÃ©trique)
- **T-Net2** : Aligne les features dans l'espace 64D (abstrait)

**8. Limites de PointNet ?**
- Ne capture **pas les relations locales** entre points voisins
- Sensible au **bruit fort** (>10%)
- RÃ©solu par **PointNet++** (Ã©chantillonnage hiÃ©rarchique)

**9. Pourquoi `sqrt(u)` pour Ã©chantillonner un disque ?**
- Compense l'augmentation de l'aire avec le rayon
- Assure une distribution **uniforme** sur le disque
- Sans sqrt : concentration au centre

### Blocs de Code Ã  MaÃ®triser

1. **T-Net** :
   - Conv1d (kernel=1) Ã— 3
   - MaxPool global
   - MLP pour prÃ©dire matrice
   - Ajout identitÃ©

2. **PointNet Forward** :
   - T-Net1 â†’ alignement spatial
   - Conv features
   - T-Net2 â†’ alignement features
   - MaxPool global
   - Classification

3. **RÃ©gularisation** :
   - Calcul de $M M^T$
   - Norme de Frobenius de $M M^T - I$

4. **Data augmentation** :
   - Bruit gaussien
   - Rotation alÃ©atoire
   - Normalisation

### Formules Importantes

**Conv1d (kernel=1)** :

$$y_i = W x_i + b$$

AppliquÃ© indÃ©pendamment Ã  chaque point $x_i$.

**MaxPool global** :

$$f = \max_{i=1}^{N} \{h(x_i)\}$$

OÃ¹ $h$ est la fonction de transformation (Conv1d + ReLU).

**T-Net regularization** :

$$L_{\text{reg}} = ||MM^T - I||_F^2 = \sum_{i,j} (MM^T - I)_{ij}^2$$

**Loss totale** :

$$L = L_{\text{classification}} + \lambda (L_{\text{reg1}} + L_{\text{reg2}})$$

Typiquement $\lambda = 0.001$.

**Ã‰chantillonnage uniforme sur disque** :

$$r = \sqrt{u_1}, \quad \theta = 2\pi u_2$$

OÃ¹ $u_1, u_2 \sim \mathcal{U}(0, 1)$.

---

## ðŸ“‹ RÃ‰SUMÃ‰ RAPIDE

### Pipeline Complet de PointNet

```
Input: Nuage de points (B, 3, N)
         â†“
    [T-Net1 3Ã—3]
  Alignement spatial
         â†“
    Conv1d (3â†’64)
         â†“
    [T-Net2 64Ã—64]
  Alignement features
         â†“
  Conv1d (64â†’1024)
         â†“
   [MaxPool Global]
  Feature globale (B, 1024)
         â†“
    MLP Classifier
         â†“
  Classes (B, 3)
```

### Comparaison avec les TPs PrÃ©cÃ©dents

| Aspect | TP1 (Neural Prior) | TP2 (Style Transfer) | TP3 (SE Block) | TP4 (PointNet) |
|--------|-------------------|---------------------|----------------|----------------|
| **Type de donnÃ©es** | Images 2D | Images 2D | Images 2D (CIFAR) | Nuages points 3D |
| **OptimisÃ©** | Poids rÃ©seau | Pixels | Poids rÃ©seau | Poids rÃ©seau |
| **MÃ©canisme clÃ©** | Prior implicite | Gram matrix | Channel attention | MaxPool + T-Net |
| **Invariance** | Aucune | Aucune | Aucune | Ordre + Rotation |
| **Dataset** | 1 image | 2 images | 50k images | Objets 3D |
| **But** | Reconstruction | Style transfer | Classification | Classification 3D |

---

## ðŸ’¡ ASTUCES POUR L'EXAMEN

### Concepts Ã  Bien Comprendre

1. **Pourquoi kernel=1 ?** â†’ Points sans structure spatiale fixe
2. **RÃ´le du MaxPool** â†’ Invariance Ã  l'ordre (permutation)
3. **IdentitÃ© dans T-Net** â†’ StabilitÃ© d'entraÃ®nement
4. **2 T-Nets** â†’ Double niveau d'alignement (spatial + features)
5. **RÃ©gularisation** â†’ Matrices orthogonales (rotations pures)
6. **sqrt(u) pour disque** â†’ Distribution uniforme

### SchÃ©mas Ã  Retenir

**Architecture T-Net** :
```
Points (3, N)
    â†“
Conv1d (kernel=1)
    â†“
MaxPool global
    â†“
MLP
    â†“
+ Identity
    â†“
Matrice (3, 3)
```

**PropriÃ©tÃ© MaxPool** :
```
Points: [p1, p2, p3]
Features: [f(p1), f(p2), f(p3)]
MaxPool: max{f(p1), f(p2), f(p3)}

Peu importe l'ordre !
```

---

**VoilÃ  ! Tu as maintenant une comprÃ©hension complÃ¨te du TP4 - PointNet** ðŸŽ‰

**RÃ©sumÃ© en 3 mots** : **Points â†’ Features â†’ Classes** !

**Points clÃ©s** :
- âœ… Conv1d kernel=1 pour points indÃ©pendants
- âœ… MaxPool global pour invariance Ã  l'ordre
- âœ… T-Net pour invariance aux rotations
- âœ… RÃ©gularisation pour matrices orthogonales

**Bon courage pour ton examen !** ðŸš€
